{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLIMENTTION\n",
        "Candidate: Doan Nguyen\n",
        "\n",
        "\n",
        "# PDF Content Extraction and Organization:\n",
        "This component is implemented using Python to read and extract content from candidate CVs stored in PDF format and organize the extracted information into an Excel file.\n",
        "\n",
        "The PDF files are stored in a folder on Google Drive.\n",
        "\n",
        "The Excel file, named Output.xlsx, is created and stored in the same folder.\n",
        "\n",
        "To run this program, please copy my OpenAI API key from the MS Word file I sent via email and paste it into the command openai.api_key = \"\" within the program."
      ],
      "metadata": {
        "id": "UdV90-IGcYJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JWKsyY3KcrN",
        "outputId": "3c5cd4d0-4ef9-4426-9371-c6d78f8dba2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# solution\n",
        "folder_path = \"/content/drive/MyDrive/UNI/VU/PDFs/\""
      ],
      "metadata": {
        "id": "uD5F1bs_Kds0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Python's current working directory\n",
        "os.chdir(folder_path)\n",
        "# Print the name and contents of the current working directory\n",
        "!pwd\n",
        "!ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR1La5hxKdwE",
        "outputId": "db6eafbb-968f-42dd-94fd-6fe3ca60e71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UNI/VU/PDFs\n",
            "total 665\n",
            "-rw------- 1 root root 154251 Aug 24 11:02 CV_DoanNguyen.pdf\n",
            "-rw------- 1 root root   2951 Oct  8 12:52 output.xlsx\n",
            "-rw------- 1 root root 325424 Oct  8 05:07 sample1.pdf\n",
            "-rw------- 1 root root 197629 Oct  8 05:07 sample2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hide output for his cell\n",
        "%%capture\n",
        "!pip install openai==0.28.0\n"
      ],
      "metadata": {
        "id": "gCw48TR4Kdzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hide output for his cell\n",
        "%%capture\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "QY8U8b0bJlac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkCFPzNjJIST"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import PyPDF2\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please copy my OpenAI key from the MS Word file (I sent via email)\n",
        "\n",
        "# Set up OpenAI API key\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "239z2XfNJVYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read PDFs and extract text\n",
        "def extract_text_from_pdfs(folder_path):\n",
        "    pdf_texts = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.pdf'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            print(f\"Processing file: {file_name}\")\n",
        "\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                text = ''\n",
        "                for page in range(len(reader.pages)):\n",
        "                    text += reader.pages[page].extract_text()\n",
        "                pdf_texts.append((file_name, text))\n",
        "    return pdf_texts"
      ],
      "metadata": {
        "id": "TRXvJLfEJVdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "# Function to process text with GPT-4 and parse JSON output\n",
        "def process_text_with_llm(text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Extract CV details and organize them into valid JSON format.\"},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    structured_info = response['choices'][0]['message']['content']\n",
        "\n",
        "    # Remove code block markers if they exist\n",
        "    cleaned_info = re.sub(r\"```json|```\", \"\", structured_info)\n",
        "\n",
        "    # Debug print statement to see the cleaned output\n",
        "    print(\"Cleaned model output:\", cleaned_info)\n",
        "\n",
        "    # Attempt to parse the cleaned JSON output\n",
        "    try:\n",
        "        structured_info_dict = json.loads(cleaned_info)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Failed to parse JSON after cleaning. Please check the model's response format.\")\n",
        "        structured_info_dict = {}  # Use an empty dictionary to avoid further errors\n",
        "\n",
        "    return structured_info_dict\n"
      ],
      "metadata": {
        "id": "wZQYtwzZQQkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save data dictionary to Excel\n",
        "def save_to_excel(data, excel_path):\n",
        "    # Convert the dictionary to a DataFrame\n",
        "    dataframe = pd.DataFrame(data)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    dataframe.to_excel(excel_path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "6xIh2kYKLsue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_data_for_excel(structured_info):\n",
        "    flattened_data = {}\n",
        "\n",
        "    # Helper function to process nested content\n",
        "    def process_nested(item):\n",
        "        if isinstance(item, dict):\n",
        "            return \"; \".join([f\"{k.capitalize()}: {process_nested(v)}\" for k, v in item.items()])\n",
        "        elif isinstance(item, list):\n",
        "            return \", \".join([process_nested(sub_item) for sub_item in item])\n",
        "        else:\n",
        "            return str(item)\n",
        "\n",
        "    # Personal Details\n",
        "    personal_info = structured_info.get('personal_details', {})\n",
        "    for key, value in personal_info.items():\n",
        "        flattened_data[f'Personal - {key.capitalize()}'] = process_nested(value)\n",
        "\n",
        "    # Process other sections dynamically\n",
        "    for section, content in structured_info.items():\n",
        "        if section != 'personal_details':  # Skip personal details as already processed\n",
        "            flattened_data[section.capitalize()] = process_nested(content)\n",
        "\n",
        "    return flattened_data\n"
      ],
      "metadata": {
        "id": "_7VVK5A1nyh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(folder_path):\n",
        "    # List all files in the folder\n",
        "    pdf_texts = extract_text_from_pdfs(folder_path)\n",
        "    output_file_path = os.path.join(folder_path, 'output.xlsx')\n",
        "\n",
        "    # Open ExcelWriter for writing to Excel file\n",
        "    with pd.ExcelWriter(output_file_path) as writer:\n",
        "        for i, (file_name, pdf_text) in enumerate(pdf_texts):\n",
        "            # Split text into chunks to avoid exceeding token limits\n",
        "            chunks = split_text_into_chunks(pdf_text, max_tokens=1000)  # Adjust chunk size to fit token limits\n",
        "            structured_info = []\n",
        "            for chunk in chunks:\n",
        "                structured_info.append(process_text_with_llm(chunk))  # Process each chunk separately\n",
        "\n",
        "            # Combine structured info and flatten for Excel output\n",
        "            combined_info = combine_chunks(structured_info)\n",
        "            flattened_data = flatten_data_for_excel(combined_info)  # Dynamically flatten based on structure\n",
        "\n",
        "            # Convert flattened data to DataFrame with each key-value as a row for flexibility\n",
        "            df = pd.DataFrame(list(flattened_data.items()), columns=['Section', 'Content'])\n",
        "            sheet_name = f\"Candidate_{i+1}\"\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    print(f\"Excel file 'output.xlsx' with each candidate in a separate sheet has been saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "2oQ_qIMMha-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_chunks(text, max_tokens=1000):\n",
        "    \"\"\"Splits text into chunks small enough for the LLM API limits.\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_tokens = 0\n",
        "    for word in words:\n",
        "        current_tokens += len(word)  # Approximate token count with word length\n",
        "        if current_tokens > max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "            current_tokens = len(word)\n",
        "        else:\n",
        "            current_chunk.append(word)\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "CBLJpLpMhcCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_chunks(chunks):\n",
        "    \"\"\"Combines processed chunks back into a single structure.\"\"\"\n",
        "    combined_info = {}\n",
        "    for chunk in chunks:\n",
        "        for key, value in chunk.items():\n",
        "            if key not in combined_info:\n",
        "                combined_info[key] = value\n",
        "            else:\n",
        "                # If it's a list, append new values, otherwise overwrite\n",
        "                if isinstance(combined_info[key], list):\n",
        "                    combined_info[key].extend(value)\n",
        "                else:\n",
        "                    combined_info[key] = value\n",
        "    return combined_info\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TORrRhzqhcbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkQtrODL_NJ",
        "outputId": "f50a8e1b-bfb3-4187-814e-4c50591c6a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: CV_DoanNguyen.pdf\n",
            "Processing file: sample1.pdf\n",
            "Processing file: sample2.pdf\n",
            "Cleaned model output: {\n",
            "  \"Name\": \"Doan Nguyen\",\n",
            "  \"Location\": \"Melbourne, Australia\",\n",
            "  \"Phone\": \"0452463137\",\n",
            "  \"Email\": \"doan310a@gmail.com\",\n",
            "  \"Website\": \"www.latrobe.edu.au/onguyen\",\n",
            "  \"Profile\": \"Dedicated educator and researcher with a PhD and a strong foundation in Information Technology and Mathematics. Over 20 years of experience in lecturing, coordinating, and designing courses for both postgraduate and undergraduate levels. Research spanning various disciplines such as Machine Learning, Data Science, Cybersecurity, and Recommender Systems.\",\n",
            "  \"Education\": [\n",
            "    {\n",
            "      \"Date\": \"Mar 2017\",\n",
            "      \"Degree\": \"Doctor of Philosophy\",\n",
            "      \"Institution\": \"Japan Advanced Institute of Science and Technology, Japan\",\n",
            "      \"Dissertation\": \"A Study on Recommender Systems Based on Dempster-Shafer Theory\"\n",
            "    },\n",
            "    {\n",
            "      \"Date\": \"Feb 2007\",\n",
            "      \"Degree\": \"Master of Engineering\",\n",
            "      \"Institution\": \"Ho Chi Minh City University of Technology, Vietnam\",\n",
            "      \"Thesis\": \"Digital Watermarking for Vietnamese Documents\"\n",
            "    },\n",
            "    {\n",
            "      \"Date\": \"Feb 2002\",\n",
            "      \"Degree\": \"Bachelor of Engineering\",\n",
            "      \"Institution\": \"Vietnam\",\n",
            "      \"Thesis\": \"Developing an Application for Managing Genealogy Using Visual Prolog\"\n",
            "    }\n",
            "  ],\n",
            "  \"Work Experience\": [\n",
            "    {\n",
            "      \"Date\": \"Jul 2023–Present\",\n",
            "      \"Position\": \"Full-time Lecturer\",\n",
            "      \"Institution\": \"Faculty of Higher Education\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"Education\": {\n",
            "    \"Institute\": \"Holmes Institute, Australia\"\n",
            "  },\n",
            "  \"ProfessionalExperience\": {\n",
            "    \"Job\": [\n",
            "      {\n",
            "        \"Company\": \"Holmes Institute\",\n",
            "        \"Role\": \"Casual Lecturer\",\n",
            "        \"StartDate\": \"Jul. 2022\",\n",
            "        \"EndDate\": \"Jun. 2023\",\n",
            "        \"Responsibilities\": [\n",
            "          {\n",
            "            \"Task\": \"Developed postgraduate subject for the Master of Information Systems program - Predictive Analytics (HI6039)\"\n",
            "          },\n",
            "          {\n",
            "            \"Task\": \"Coordinated and lectured ten postgraduate subjects for the Master of Information Systems program\"\n",
            "          },\n",
            "          {\n",
            "            \"Task\": \"Coordinated and lectured seven undergraduate subjects for the Bachelor of Information Systems program\"\n",
            "          }\n",
            "        ],\n",
            "        \"SubjectsCoordinatedAndLectured\": [\n",
            "          \"Business Analytics Fundamentals (HI6037)\",\n",
            "          \"Business Intelligence and Knowledge Management (HS3041) (Coordinated only)\",\n",
            "          \"Leveraging IT for Business Advantage (HI6032) (Lectured only)\",\n",
            "          \"Predictive Analytics (HI6039)\",\n",
            "          \"Artificial Intelligence and Machine Learning (HI6040)\",\n",
            "          \"Systems Analysis and Design (HI5030)\",\n",
            "          \"Enterprise Information Systems(HI6034)\",\n",
            "          \"Database Design (HI5033)\",\n",
            "          \"Information Systems Project Management (HI5029)\",\n",
            "          \"Professional Issues in IS Ethics & Practice (HI5031) (Lectured only)\",\n",
            "          \"Strategic Information Systems Management (HS3021) (Lectured only)\",\n",
            "          \"Information Technology for Business (HC1041) (Coordinated and lectured)\"\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"Education\": [\n",
            "    {\n",
            "      \"CourseName\": \"Web Design\",\n",
            "      \"CourseCode\": \"HS1021\"\n",
            "    },\n",
            "    {\n",
            "      \"CourseName\": \"Database Design and Use\",\n",
            "      \"CourseCode\": \"HS2021\"\n",
            "    },\n",
            "    {\n",
            "      \"CourseName\": \"Introduction to Programming\",\n",
            "      \"CourseCode\": \"HS1031\"\n",
            "    },\n",
            "    {\n",
            "      \"CourseName\": \"Data Communications and Networks\",\n",
            "      \"CourseCode\": \"HS1011\"\n",
            "    },\n",
            "    {\n",
            "      \"CourseName\": \"Human-Computer Interaction\",\n",
            "      \"CourseCode\": \"HS2031\"\n",
            "    }\n",
            "  ],\n",
            "  \"WorkExperience\": [\n",
            "    {\n",
            "      \"Duration\": \"Feb. 2023–Jun. 2023\",\n",
            "      \"Position\": \"Casual Lecturer\",\n",
            "      \"Organization\": \"Department of Computer Science & Computer Engineering, La Trobe University, Australia\",\n",
            "      \"Description\": \"At La Trobe University, I worked as a casual lecturer for one semester.\",\n",
            "      \"CoursesLectured\": [\n",
            "        \"Artificial Intelligence: Logic and Reasoning (CSE4ALR)\",\n",
            "        \"Deep Learning (CSE5DL)\",\n",
            "        \"Data Mining (CSE5DMI)\",\n",
            "        \"Big Data Management on the Cloud (CSE5BDC)\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Duration\": \"Aug. 2021–May 2022\",\n",
            "      \"Position\": \"Full-time Postdoc\",\n",
            "      \"Organization\": \"La Trobe Cybersecurity Research Hub, The Department of Computer Science and Information Technology, La Trobe University, Australia\",\n",
            "      \"Description\": \"During this period at La Trobe University, I worked on the project entitled 'Anomaly Detection in IoT for Satellite Security Using Blockchain'.\",\n",
            "      \"Accomplishments\": [\n",
            "        \"Developed a new solution for applying Blockchain and Multi-Centre Federating Learning to detect anomalies in the IoT system communicating through satellites.\",\n",
            "        \"Developed a new method to select IoT devices to join the Federated Learning process.\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"ProfessionalExperience\": [\n",
            "    {\n",
            "      \"Position\": \"Full-time Postdoc\",\n",
            "      \"Company\": \"Data Science Group, National Institute for Materials Science, Japan\",\n",
            "      \"Period\": \"Apr. 2018–Mar. 2020\",\n",
            "      \"Projects\": [\n",
            "        {\n",
            "          \"Title\": \"Materials Research by Information Integration Initiative (MI2I)\",\n",
            "          \"Accomplishments\": [\n",
            "            \"Developed a new heuristic method to aggregate a Federated Machine Learning model from a list of Machine Learning models trained locally on selected IoT devices\",\n",
            "            \"Developed a new framework, called Two-Body Approximation, for flexibly designing and generating descriptors to represent crystalline materials\",\n",
            "            \"Applied K-Nearest Neighbors and Kernel Ridge Regressions for predicting formation energies of materials presented by the descriptors which were generated by the framework\",\n",
            "            \"Developed a new solution to predict the high-entropy state of random alloys using Dempster-Shafer theory and popular Machine Learning techniques in classification\"\n",
            "          ],\n",
            "          \"TechnologiesUsed\": [\"Python\", \"TensorFlow\", \"scikit-learn\", \"Pymatgen\"]\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Position\": \"Full-time Postdoc\",\n",
            "      \"Company\": \"Graduate School of Advanced Science and Technology\",\n",
            "      \"Period\": \"May 2017–Mar. 2018\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"Education\": [\n",
            "    {\n",
            "      \"Institution\": \"Japan Advanced Institute of Science and Technology, Japan\",\n",
            "      \"Accomplishments\": [\n",
            "        {\n",
            "          \"Description\": \"Developed a new descriptor, called Extended Orbital Field Matrix, for representing crystalline materials.\"\n",
            "        },\n",
            "        {\n",
            "          \"Description\": \"Developed another new descriptor based on chemical bonds among atoms for representing crystalline materials.\"\n",
            "        },\n",
            "        {\n",
            "          \"Description\": \"Applied K-Nearest Neighbors and Kernel Ridge Regressions for predicting formation energies of materials presented by the developed descriptors.\"\n",
            "        },\n",
            "        {\n",
            "          \"Description\": \"Conducted experiments by using Python, scikit-learn, and Pymatgen.\"\n",
            "        }\n",
            "      ],\n",
            "      \"Project\": \"MI2I\"\n",
            "    }\n",
            "  ],\n",
            "  \"WorkExperience\": [\n",
            "    {\n",
            "      \"StartDate\": \"May 2007\",\n",
            "      \"EndDate\": \"Mar. 2013\",\n",
            "      \"JobTitle\": \"Full-time Lecturer\",\n",
            "      \"Organization\": \"Faculty of Computer Science and Engineering, Ho Chi Minh City University of Technology, Vietnam\",\n",
            "      \"Accomplishments\": [\n",
            "        {\n",
            "          \"Description\": \"Lectured six undergraduate subjects: Database Systems, Electronic Commerce, Data Structures and Algorithms, Algorithms Analysis and Design, Programming Methodology, and Introduction to Information Technology.\"\n",
            "        },\n",
            "        {\n",
            "          \"Description\": \"Supervised undergraduate students on their projects.\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Cleaned model output: {\n",
            "    \"Work Experience\": [\n",
            "        {\n",
            "            \"JobTitle\": \"Chief Investigator\",\n",
            "            \"Project\": \"Development of new solution for applying watermarking techniques to a vector-based 2D map\",\n",
            "            \"Duties\": \"Lead investigator\"\n",
            "        },\n",
            "        {\n",
            "            \"JobTitle\": \"Co-Chief Investigator\",\n",
            "            \"Project\": \"Development of a solution for the copyright protection of books written in the Vietnamese language\",\n",
            "            \"Duties\": \"Co-lead investigator\"\n",
            "        },\n",
            "        {\n",
            "            \"JobTitle\": \"Full-time Lecturer\",\n",
            "            \"Institution\": \"NIIT Hoa Sen, Hoa Sen University, Vietnam\",\n",
            "            \"Dates\": \"Dec. 2004–Jan. 2007\",\n",
            "            \"Duties\": \"Lectured and supervised students who were in the International Programmer Training Program and pursuing D-NIIT certificate\"\n",
            "        },\n",
            "        {\n",
            "            \"JobTitle\": \"Full-time Developer\",\n",
            "            \"Institution\": \"Center for Developing Information Technology and Geographic Information System, Ho Chi Minh City University of Technology, Vietnam\",\n",
            "            \"Dates\": \"Feb. 2002–Nov. 2004\",\n",
            "            \"Duties\": \"Developed for projects in the field of Geographic Information Systems\"\n",
            "        }\n",
            "    ],\n",
            "    \"Computer Skills\": [\n",
            "        {\n",
            "            \"AI/ML\": [\"Google Colab\", \"Jupyter Notebook\", \"TensorFlow\", \"PyTorch\", \"GitHub\"],\n",
            "            \"Programming Languages\": [\"Python\", \"C++\", \"C\", \"C#\", \"SQL\", \"Visual Prolog\"],\n",
            "            \"DBMSs\": [\"Microsoft SQL Server\", \"Oracle\", \"PostgreSQL\"]\n",
            "        }\n",
            "    ],\n",
            "    \"Selected Publications\": [\n",
            "        {\n",
            "            \"Year\": \"2024\",\n",
            "            \"Authors\": \"Nguyen, V.D., Diro, A.A., Chilamkurti, N.K., Heyne, W. and Phan, K.T.\",\n",
            "            \"Title\": \"A Novel Blockchain-Enabled Federated Learning Scheme for IoT\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "Cleaned model output: {\n",
            "\"Publications\": [\n",
            "    {\n",
            "        \"Title\": \"Anomaly Detection\",\n",
            "        \"Journal\": \"IEEE Transactions on Emerging Topics in Computational Intelligence\",\n",
            "        \"Status\": \"Major Revision\",\n",
            "        \"Year\": \"2024\",\n",
            "        \"Authors\": [\"Pham, D.\", \"Phan, K.T.\", \"Abuadbba, S.\", \"Nguyen, V.D.\", \"Chilamkurti, N.K.\"]\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"Split Learning without Local Weight Sharing to Enhance Client-side Data Privacy\", \n",
            "        \"Journal\": \"IEEE Transactions on Dependable and Secure Computing\",\n",
            "        \"Status\": \"Major Revision\",\n",
            "        \"Year\": \"2021\",\n",
            "        \"Authors\": [\"Pham, D.\", \"Phan, K.T.\", \"Abuadbba, S.\", \"Nguyen, V.D.\", \"Chilamkurti, N.K.\"]\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"A Comprehensive Study of Anomaly Detection Schemes in IoT Networks Using Machine Learning Algorithms\",\n",
            "        \"Journal\": \"Sensors\",\n",
            "        \"Volume\": \"21\",\n",
            "        \"Issue\":\"24\",\n",
            "        \"Page\": \"8320\",\n",
            "        \"Year\": \"2020\",\n",
            "        \"Authors\": [\"Diro, A.A.\", \"Chilamkurti, N.K.\", \"Nguyen, V.D.\", \"Heyne, W.\"]\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"Integrating Community Context Information into a Reliably Weighted Collaborative Filtering System Using Soft Ratings\",\n",
            "        \"Journal\": \"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\n",
            "        \"Volume\": \"50\",\n",
            "        \"Issue\":\"4\",\n",
            "        \"Page\": \"1318–1330\",\n",
            "        \"Year\": \"2019\",\n",
            "        \"Authors\": [\"Nguyen, V.D.\", \"Huynh, V.N.\", \"Sriboonchitta, S.\"]\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"Application of Materials Informatics on Crystalline Materials for Two-Body Terms Approximation\",\n",
            "        \"Journal\": \"Computational Materials Science\",\n",
            "        \"Volume\": \"166\",\n",
            "        \"Page\": \"155-161\",\n",
            "        \"Year\": \"2018\",\n",
            "        \"Authors\": [\"Nguyen, V.D.\", \"Pham, T.L.\", \"Dam, H.C.\"]\n",
            "    },\n",
            "    {\n",
            "        \"Title\": \"Learning Structure-Property Relationship in Crystalline Materials\",\n",
            "        \"Authors\": [\"Pham, T.L.\", \"Nguyen, D.N.\", \"Nguyen, V.D.\", \"Kino, H.\", \"Miyake, T.\", \"Dam, H.C.\"]\n",
            "    }\n",
            "]\n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"Publications\": [\n",
            "    {\n",
            "      \"Title\": \"Study of Lanthanide-Transition Metal Alloys\",\n",
            "      \"Journal\": \"The Journal of Chemical Physics\",\n",
            "      \"Volume\": \"148\",\n",
            "      \"Issue\": \"20\",\n",
            "      \"Pages\": \"204106\",\n",
            "      \"Year\": \"2017\",\n",
            "      \"Authors\": [\n",
            "        \"Nguyen, V.D.\",\n",
            "        \"Huynh, V.N.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Title\": \"Using Community Preference for Solving Sparsity and Cold-Start Problems in Collaborative Filtering Approach\",\n",
            "      \"Journal\": \"Electronic Commerce Research and Applications\",\n",
            "      \"Volume\": \"26\",\n",
            "      \"Pages\": \"101-108\",\n",
            "      \"Year\": \"2017\",\n",
            "      \"Authors\": [\n",
            "        \"Nguyen, V.D.\",\n",
            "        \"Huynh, V.N.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Title\": \"Two-Probabilities Focused Combination in Recommender Systems\",\n",
            "      \"Journal\": \"International Journal of Approximate Reasoning\",\n",
            "      \"Volume\": \"80\",\n",
            "      \"Pages\": \"225-238\",\n",
            "      \"Year\": \"2017\",\n",
            "      \"Authors\": [\n",
            "        \"Nguyen, V.D.\",\n",
            "        \"Huynh, V.N.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"References\": [\n",
            "    {\n",
            "      \"Name\": \"Professor Naveen Chilamkurti\",\n",
            "      \"Affiliation\": \"La Trobe University, Australia\",\n",
            "      \"Phone\": \"+61394791269\",\n",
            "      \"Email\": \"n.chilamkurti@latrobe.edu.au\",\n",
            "      \"Homepage\": \"https://scholars.latrobe.edu.au/nkchilamkurt\"\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Dr. Abebe Diro\",\n",
            "      \"Affiliation\": \"Lecturer, RMIT University, Australia\",\n",
            "      \"Phone\": \"+61399254132\",\n",
            "      \"Email\": \"abebe.diro3@rmit.edu.au\",\n",
            "      \"Homepage\": \"https://academics.rmit.edu.au/abebe-diro3\"\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Professor Van-Nam Huynh\",\n",
            "      \"Affiliation\": \"Japan Advanced Institute of Science and Technology, Japan\",\n",
            "      \"Phone\": \"+81761511791\",\n",
            "      \"Email\": \"huynh@jaist.ac.jp\",\n",
            "      \"Homepage\": \"https://www.jaist.ac.jp/∼huynh\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Cleaned model output: {\n",
            "  \"Name\": \"John Doe\",\n",
            "  \"Location\": \"Your Location\",\n",
            "  \"Email\": \"youremail@yourdomain.com\",\n",
            "  \"Phone\": \"0541 999 99 99\",\n",
            "  \"Website\": \"yourwebsite.com\",\n",
            "  \"Linkedin\": \"yourusername\",\n",
            "  \"Github\": \"yourusername\",\n",
            "  \"Profile Details\": \"Welcome to RenderCV! RenderCV is a LaTeX-based CV/resume version-control and maintenance app. It allows you to create a high-quality CV or resume as a PDF file from a YAML file, with Markdown syntax support and complete control over the LaTeX code. The boilerplate content was inspired by Gayle McDowell.\",\n",
            "  \"Quick Guide\": {\n",
            "    \"Each section title is arbitrary and each section contains a list of entries.\": [\n",
            "      \"BulletEntry\",\n",
            "      \"TextEntry\",\n",
            "      \"EducationEntry\",\n",
            "      \"ExperienceEntry\",\n",
            "      \"NormalEntry\",\n",
            "      \"PublicationEntry\",\n",
            "      \"OneLineEntry\"\n",
            "    ],\n",
            "    \"Select a section title, pick an entry type, and start writing your section!\": \"Here, you can find a comprehensive user guide for RenderCV.\"\n",
            "  },\n",
            "  \"Education\": {\n",
            "    \"University\": \"University of Pennsylvania\",\n",
            "    \"Degree\": \"BS\",\n",
            "    \"Major\": \"Computer Science\",\n",
            "    \"GPA\": \"3.9/4.0\",\n",
            "    \"Coursework\": [\n",
            "      \"Computer Architecture\",\n",
            "      \"Comparison of Learning Algorithms\",\n",
            "      \"Computational Theory\"\n",
            "    ],\n",
            "    \"Period\": \"Sept 2000 – May 2005\"\n",
            "  },\n",
            "  \"Experience\": {\n",
            "    \"Company\": \"Apple\",\n",
            "    \"Position\": \"Software\"\n",
            "  }\n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"Personal_Info\": {\n",
            "    \"Name\": \"John Doe\",\n",
            "    \"Last_Updated\": \"September 2024\"\n",
            "  },\n",
            "  \"Experience\": [\n",
            "    {\n",
            "      \"Job_Title\": \"Engineer\",\n",
            "      \"Location\": \"Cupertino, CA\",\n",
            "      \"Duration\": \"June 2005 - Aug 2007\",\n",
            "      \"Responsibilities_and_Achievements\": [\n",
            "        \"Reduced time to render user buddy lists by 75% by implementing a prediction algorithm\",\n",
            "        \"Integrated iChat with Spotlight Search by creating a tool to extract metadata from saved chat transcripts and provide metadata to a system-wide search database\",\n",
            "        \"Redesigned chat file format and implemented backward compatibility for search\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Job_Title\": \"Software Engineer Intern\",\n",
            "      \"Company\": \"Microsoft\",\n",
            "      \"Location\": \"Redmond, WA\",\n",
            "      \"Duration\": \"June 2003 - Aug 2003\",\n",
            "      \"Responsibilities_and_Achievements\": [\n",
            "        \"Designed a UI for the VS open file switcher (Ctrl-Tab) and extended it to tool windows\",\n",
            "        \"Created a service to provide gradient across VS and VS add-ins, optimizing its performance via caching\",\n",
            "        \"Built an app to compute the similarity of all methods in a codebase, reducing the time from O(n2) to O(nlogn)\",\n",
            "        \"Created a test case generation tool that creates random XML docs from XML Schema\",\n",
            "        \"Automated the extraction and processing of large datasets from legacy systems using SQL and Perl scripts\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"Publications\": [\n",
            "    {\n",
            "      \"Title\": \"3D Finite Element Analysis of No-Insulation Coils\",\n",
            "      \"Authors\": [\n",
            "        \"Frodo Baggins\",\n",
            "        \"John Doe\",\n",
            "        \"Samwise Gamgee\"\n",
            "      ],\n",
            "      \"Publication_Link\": \"/external-link-altJan 2004\",\n",
            "      \"DOI\": \"10.1109/TASC.2023.3340648\"\n",
            "    }\n",
            "  ],\n",
            "  \"Projects\": [\n",
            "    {\n",
            "      \"Project_Name\": \"Multi-User Drawing Tool\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Cleaned model output: {\n",
            "    \"Projects\": [\n",
            "        {\n",
            "            \"Title\": \"Electronic Classroom\",\n",
            "            \"Description\": \"Developed an electronic classroom where multiple users can simultaneously view and draw on a 'chalkboard' with each person’s edits synchronized.\",\n",
            "            \"Tools Used\": [\"C++\", \"MFC\"],\n",
            "            \"Github link\": \"github.com/name/repo\"\n",
            "        },\n",
            "        {\n",
            "            \"Title\": \"Synchronized Desktop Calendar\",\n",
            "            \"Description\": \"Developed a desktop calendar with globally shared and synchronized calendars, allowing users to schedule meetings with other users.\",\n",
            "            \"Tools Used\": [\"C#\", \".NET\", \"SQL\", \"XML\"],\n",
            "            \"Github link\": \"github.com/name/repo\"\n",
            "        },\n",
            "        {\n",
            "            \"Title\": \"Custom Operating System\",\n",
            "            \"Description\": \"Built a UNIX-style OS with a scheduler, file system, text editor, and calculator.\",\n",
            "            \"Tools Used\": [\"C2002\"],\n",
            "            \"Github link\": \"N/A\"\n",
            "        }\n",
            "    ],\n",
            "    \"Languages\": [\"C++\", \"C\", \"Java\", \"Objective-C\", \"C#\", \"SQL\", \"JavaScript\"],\n",
            "    \"Technologies\": [\".NET\", \"Microsoft SQL Server\", \"XCode\", \"Interface Builder\"],\n",
            "    \"Name\": \"John Doe\"\n",
            "}\n",
            "Cleaned model output: {\n",
            "    \"Name\": \"MARISSA MAYER\",\n",
            "    \"Occupation\": \"Business Woman & Proud Geek\",\n",
            "    \"Contact\": {\n",
            "        \"Email\": \"mmayer@yahoo-inc.com\",\n",
            "        \"Address\": \"Street, 00000 County, Sunnyvale, CA\",\n",
            "        \"LinkedIn\": \"@marissamayer\",\n",
            "        \"Tumblr\": \"marissamayr.tumblr.com\",\n",
            "        \"Twitter\": \"@marissamayer\"\n",
            "    },  \n",
            "    \"Experience\": [\n",
            "        {\n",
            "            \"JobTitle\": \"President & CEO\",\n",
            "            \"Company\": \"Yahoo!\",\n",
            "            \"Dates\": \"July 2012 – Ongoing\",\n",
            "            \"Location\": \"Sunnyvale, CA\",\n",
            "            \"Responsibilities\": [\n",
            "                \"Led the $5 billion acquisition of the company with Verizon\",\n",
            "                \"Acquired Tumblr for $1.1 billion and moved the company’s blog there\",\n",
            "                \"Built Yahoo’s mobile, video and social businesses from nothing in 2011 to $1.6 billion in GAAP revenue in 2015\",\n",
            "                \"Tripled the company’s mobile base to over 600 million monthly active users and generated over $1 billion of mobile advertising revenue\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"JobTitle\": \"Vice President of Location & Services\",\n",
            "            \"Company\": \"Google\",\n",
            "            \"Dates\": \"Oct 2010 – July 2012\",\n",
            "            \"Location\": \"Palo Alto, CA\",\n",
            "            \"Responsibilities\": [\n",
            "                \"Position Google Maps as the world leader in mobile apps and navigation\",\n",
            "                \"Oversaw 1000+ engineers and product managers working on Google Maps, Google Places and Google Earth\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"JobTitle\": \"Vice President of Search Products & UX\",\n",
            "            \"Company\": \"Google\",\n",
            "            \"Dates\": \"2005 – 2010\",\n",
            "            \"Location\": \"Palo Alto, CA\"\n",
            "        },\n",
            "        {\n",
            "            \"JobTitle\": \"Product Manager & UI Lead\",\n",
            "            \"Company\": \"Google\",\n",
            "            \"Dates\": \"Oct 2001 – July 2005\",\n",
            "            \"Location\": \"Palo Alto, CA\"\n",
            "        }\n",
            "    ]    \n",
            "}\n",
            "Cleaned model output: {\n",
            "  \"Experience\": {\n",
            "    \"Google\": {\n",
            "      \"Position\": \"Lead of Product Management and User Interaction teams\",\n",
            "      \"Appointed by\": \"Larry Page\",\n",
            "      \"Year\": \"2001\",\n",
            "      \"Responsibilities\": [\n",
            "        \"Optimized Google’s homepage\",\n",
            "        \"A/B tested every minor detail to increase usability (incl. spacing between words, color schemes and pixel-by-pixel element alignment)\"\n",
            "      ]\n",
            "    },\n",
            "    \"Yahoo!\": {\n",
            "      \"Role\": \"Business Development\",\n",
            "      \"Responsibilities\": [\n",
            "        \"Resolving issues with Yahoo! investors\",\n",
            "        \"Showing Yahoo! employees that their work has meaning\",\n",
            "        \"Business development for Yahoo! after the Verizon acquisition\"\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"Life Philosophy\": \"If you don’t have any shadows, you’re not standing in the light.\",\n",
            "  \"Achievements\": {\n",
            "    \"Personal\": {\n",
            "      \"Courage to take sinking ship and try to make it float\",\n",
            "      \"Persistence & Loyalty shown during hard moments and willingness to stay with Yahoo after the acquisition\"\n",
            "    },\n",
            "    \"Professional\": {\n",
            "      \"Successful in growing Google's user base from hundred thousand searches per day to over a billion\",\n",
            "      \"Acknowledged as Youngest CEO on Fortune’s list of 50 most powerful women\"\n",
            "    }\n",
            "  },\n",
            "  \"Strengths\": [\n",
            "    \"Hard-working\",\n",
            "    \"Persuasive\",\n",
            "    \"Motivator & Leader\",\n",
            "    \"UX\",\n",
            "    \"Mobile Devices & Applications\",\n",
            "    \"Product Management & Marketing\"\n",
            "  ],\n",
            "  \"Languages\": [\n",
            "    \"English\"\n",
            "  ]\n",
            "}\n",
            "Error: Failed to parse JSON after cleaning. Please check the model's response format.\n",
            "Cleaned model output: {\n",
            "  \"Languages\": {\n",
            "    \"Spanish\": \"Proficient\",\n",
            "    \"German\": \"Fluent\"\n",
            "  },\n",
            "  \"Education\": [\n",
            "    {\n",
            "      \"Degree\": \"M.S. in Computer Science\",\n",
            "      \"Institution\": \"Stanford University\",\n",
            "      \"Dates\": \"Sept 1997 – June 1999\"\n",
            "    },\n",
            "    {\n",
            "      \"Degree\": \"B.S. in Symbolic Systems\",\n",
            "      \"Institution\": \"Stanford University\",\n",
            "      \"Dates\": \"Sept 1993 – June 1997\"\n",
            "    }\n",
            "  ],\n",
            "  \"Publications\": {\n",
            "    \"Books\": [\n",
            "      {\n",
            "        \"Authors\": [\"E. Someone\", \"T. Lim\"],\n",
            "        \"Title\": \"A Fictional Research\",\n",
            "        \"PublicationPlace\": \"Somewhere, Some Place\",\n",
            "        \"Date\": \"2010\"\n",
            "      }\n",
            "    ],\n",
            "    \"JournalArticles\": [\n",
            "      {\n",
            "        \"Authors\": [\"L. T. Wong\", \"E. Someone\"],\n",
            "        \"Title\": \"A non-existant paper\",\n",
            "        \"Journal\": \"Journal of Carrying On\",\n",
            "        \"Volume\": \"12\",\n",
            "        \"Date\": \"2011\"\n",
            "      },\n",
            "      {\n",
            "        \"Authors\": [\"L. T. Lim\", \"E. Someone\", \"A. Other\"],\n",
            "        \"Title\": \"A study into fireside story-telling\",\n",
            "        \"Journal\": \"Journal of Carrying On\",\n",
            "        \"Volume\": \"7\",\n",
            "        \"Date\": \"2008\"\n",
            "      }\n",
            "    ],\n",
            "    \"ConferenceProceedings\": [\n",
            "      {\n",
            "        \"Authors\": [\"E. Someone\", \"L. T. Lim\"],\n",
            "        \"Title\": \"Another paper something something\",\n",
            "        \"Conference\": \"72nd AmaZing Conference\",\n",
            "        \"Location\": \"Far Far Away\",\n",
            "        \"Date\": \"2013\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"Referees\": [\n",
            "    {\n",
            "      \"Name\": \"Prof. Alpha Beta\",\n",
            "      \"Institution\": \"@Institute\",\n",
            "      \"Email\": \"a.beta@university.edu\",\n",
            "      \"Address\": [\n",
            "        \"Address Line 1\",\n",
            "        \"Address line 2\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"Name\": \"Prof. Gamma Delta\",\n",
            "      \"Institution\": \"@Institute\",\n",
            "      \"Email\": \"g.delta@university.edu\",\n",
            "      \"Address\": [\n",
            "        \"Address Line 1\",\n",
            "        \"Address line 2\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Excel file 'output.xlsx' with each candidate in a separate sheet has been saved to /content/drive/MyDrive/UNI/VU/PDFs/output.xlsx\n"
          ]
        }
      ]
    }
  ]
}