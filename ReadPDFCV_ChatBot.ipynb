{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JWKsyY3KcrN",
        "outputId": "d52c4226-2756-480e-87f9-5b98f75e4304"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# solution\n",
        "folder_path = \"/content/drive/MyDrive/UNI/VU/PDFs/\""
      ],
      "metadata": {
        "id": "uD5F1bs_Kds0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Python's current working directory\n",
        "os.chdir(folder_path)\n",
        "# Print the name and contents of the current working directory\n",
        "!pwd\n",
        "!ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR1La5hxKdwE",
        "outputId": "1de70637-d7a1-4a70-e3b6-9f40059f4223"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UNI/VU/PDFs\n",
            "total 683\n",
            "-rw------- 1 root root 154251 Aug 24 11:02 CV_DoanNguyen.pdf\n",
            "-rw------- 1 root root  21484 Oct  4 17:57 output.xlsx\n",
            "-rw------- 1 root root 325424 Oct  4 17:17 sample1.pdf\n",
            "-rw------- 1 root root 197629 Oct  4 17:17 sample2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hide output for his cell\n",
        "%%capture\n",
        "!pip install openai==0.28.0\n"
      ],
      "metadata": {
        "id": "gCw48TR4Kdzf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hide output for his cell\n",
        "%%capture\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "QY8U8b0bJlac"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EkCFPzNjJIST"
      },
      "outputs": [],
      "source": [
        "\n",
        "import openai\n",
        "import PyPDF2\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up OpenAI API key\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "239z2XfNJVYs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read PDFs and extract text\n",
        "def extract_text_from_pdfs(folder_path):\n",
        "    pdf_texts = []\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.pdf'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            print(f\"Processing file: {file_name}\")\n",
        "\n",
        "            with open(file_path, 'rb') as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                text = ''\n",
        "                for page in range(len(reader.pages)):\n",
        "                    text += reader.pages[page].extract_text()\n",
        "                pdf_texts.append((file_name, text))\n",
        "    return pdf_texts"
      ],
      "metadata": {
        "id": "TRXvJLfEJVdj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "# Function to process text with GPT-4o and parse JSON output\n",
        "def process_text_with_llm(text):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Extract CV details and organize them into valid JSON format.\"},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    structured_info = response['choices'][0]['message']['content']\n",
        "\n",
        "    # Remove code block markers if they exist\n",
        "    cleaned_info = re.sub(r\"```json|```\", \"\", structured_info)\n",
        "\n",
        "    # Debug print statement to see the cleaned output\n",
        "    print(\"Cleaned model output:\", cleaned_info)\n",
        "\n",
        "    # Attempt to parse the cleaned JSON output\n",
        "    try:\n",
        "        structured_info_dict = json.loads(cleaned_info)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: Failed to parse JSON after cleaning. Please check the model's response format.\")\n",
        "        structured_info_dict = {}  # Use an empty dictionary to avoid further errors\n",
        "\n",
        "    return structured_info_dict\n"
      ],
      "metadata": {
        "id": "wZQYtwzZQQkA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example modification for extract_to_dataframe to handle list of tuples\n",
        "def extract_to_dataframe(pdf_texts):\n",
        "    data = {\n",
        "        'File Name': [],\n",
        "        'Name': [],\n",
        "        'Job Experience': [],\n",
        "        'Education': []\n",
        "    }\n",
        "\n",
        "    # Iterate over list of (file_name, pdf_text) tuples\n",
        "    for file_name, pdf_text in pdf_texts:\n",
        "        structured_info = process_text_with_llm(pdf_text)\n",
        "\n",
        "        # Append data from dictionary if available, or handle missing keys\n",
        "        data['File Name'].append(file_name)\n",
        "        data['Name'].append(structured_info.get('Name', 'N/A'))\n",
        "        data['Job Experience'].append(structured_info.get('Job Experience', 'N/A'))\n",
        "        data['Education'].append(structured_info.get('Education', 'N/A'))\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "mon1s_vaOBiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to convert structured data to DataFrame\n",
        "def extract_to_dataframe(pdf_texts):\n",
        "    data = {'File Name': [], 'Name': [], 'Job Experience': [], 'Education': [], 'Skills': []}\n",
        "\n",
        "    for file_name, text in pdf_texts:\n",
        "        structured_info = process_text_with_llm(text)\n",
        "        # Assuming the structured information is returned as a dictionary\n",
        "        data['File Name'].append(file_name)\n",
        "        data['Name'].append(structured_info.get('Name'))\n",
        "        data['Job Experience'].append(structured_info.get('Job Experience'))\n",
        "        data['Education'].append(structured_info.get('Education'))\n",
        "        data['Skills'].append(structured_info.get('Skills'))\n",
        "\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "xJVzs_jLLnTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save data dictionary to Excel\n",
        "def save_to_excel(data, excel_path):\n",
        "    # Convert the dictionary to a DataFrame\n",
        "    dataframe = pd.DataFrame(data)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    dataframe.to_excel(excel_path, index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6xIh2kYKLsue"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_data_for_excel(structured_info):\n",
        "    flattened_data = {}\n",
        "\n",
        "    # Helper function to process nested content\n",
        "    def process_nested(item):\n",
        "        if isinstance(item, dict):\n",
        "            return \"; \".join([f\"{k.capitalize()}: {process_nested(v)}\" for k, v in item.items()])\n",
        "        elif isinstance(item, list):\n",
        "            return \", \".join([process_nested(sub_item) for sub_item in item])\n",
        "        else:\n",
        "            return str(item)\n",
        "\n",
        "    # Personal Details\n",
        "    personal_info = structured_info.get('personal_details', {})\n",
        "    for key, value in personal_info.items():\n",
        "        flattened_data[f'Personal - {key.capitalize()}'] = process_nested(value)\n",
        "\n",
        "    # Process other sections dynamically\n",
        "    for section, content in structured_info.items():\n",
        "        if section != 'personal_details':  # Skip personal details as already processed\n",
        "            flattened_data[section.capitalize()] = process_nested(content)\n",
        "\n",
        "    return flattened_data\n"
      ],
      "metadata": {
        "id": "_7VVK5A1nyh7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "new code"
      ],
      "metadata": {
        "id": "IDioQeXyLrjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main(folder_path):\n",
        "    pdf_texts = extract_text_from_pdfs(folder_path)\n",
        "    output_file_path = os.path.join(folder_path, 'output.xlsx')\n",
        "\n",
        "    with pd.ExcelWriter(output_file_path) as writer:\n",
        "        for i, (file_name, pdf_text) in enumerate(pdf_texts):\n",
        "            structured_info = process_text_with_llm(pdf_text)  # Process PDF to get structured data\n",
        "            flattened_data = flatten_data_for_excel(structured_info)  # Dynamically flatten based on structure\n",
        "\n",
        "            # Convert flattened data to DataFrame with each key-value as a row for flexibility\n",
        "            df = pd.DataFrame(list(flattened_data.items()), columns=['Section', 'Content'])\n",
        "            sheet_name = f\"CV_{i+1}\"\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    print(f\"Excel file 'output.xlsx' with each CV in a separate sheet has been saved to {output_file_path}\")\n",
        "\n",
        "# Run the updated process\n",
        "main(folder_path)\n"
      ],
      "metadata": {
        "id": "8Q4JL0MmJNPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31964d53-0df6-4484-e1b1-43b6ccf30969"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: CV_DoanNguyen.pdf\n",
            "Processing file: sample1.pdf\n",
            "Processing file: sample2.pdf\n",
            "Cleaned model output: \n",
            "{\n",
            "  \"personal_information\": {\n",
            "    \"name\": \"Doan Nguyen\",\n",
            "    \"location\": \"Melbourne, Australia\",\n",
            "    \"phone\": \"H0452463137\",\n",
            "    \"email\": \"bdoan310a@gmail.com\",\n",
            "    \"website\": \"www.latrobe.edu.au/onguyen\"\n",
            "  },\n",
            "  \"summary\": \"Dedicated educator and researcher with a PhD and a strong foundation in Information Technology and Mathematics. Over 20 years of experience in lecturing, coordinating, and designing courses for both postgraduate and undergraduate levels. Research spans disciplines such as Machine Learning, Data Science, Cybersecurity, and Recommender Systems.\",\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Doctor of Philosophy\",\n",
            "      \"institution\": \"Japan Advanced Institute of Science and Technology\",\n",
            "      \"location\": \"Japan\",\n",
            "      \"date\": \"Mar. 2017\",\n",
            "      \"dissertation\": \"A Study on Recommender Systems Based on Dempster-Shafer Theory\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Master of Engineering\",\n",
            "      \"institution\": \"Ho Chi Minh City University of Technology\",\n",
            "      \"location\": \"Vietnam\",\n",
            "      \"date\": \"Feb. 2007\",\n",
            "      \"thesis\": \"Digital Watermarking for Vietnamese Documents\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Engineering\",\n",
            "      \"location\": \"Vietnam\",\n",
            "      \"date\": \"Feb. 2002\",\n",
            "      \"thesis\": \"Developing an Application for Managing Genealogy Using Visual Prolog\"\n",
            "    }\n",
            "  ],\n",
            "  \"work_experience\": [\n",
            "    {\n",
            "      \"title\": \"Full-time Lecturer\",\n",
            "      \"institution\": \"Faculty of Higher Education, Holmes Institute\",\n",
            "      \"location\": \"Australia\",\n",
            "      \"date\": \"Jul. 2023–Present\",\n",
            "      \"responsibilities\": [\n",
            "        \"Developed one postgraduate subject for the Master of Information Systems program: Predictive Analytics (HI6039)\",\n",
            "        \"Coordinated and lectured ten postgraduate subjects\",\n",
            "        \"Coordinated and lectured seven undergraduate subjects\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Casual Lecturer\",\n",
            "      \"institution\": \"Holmes Institute\",\n",
            "      \"location\": \"Australia\",\n",
            "      \"date\": \"Jul. 2022–Jun. 2023\",\n",
            "      \"responsibilities\": [\n",
            "        \"Lectured postgraduate subjects in the Master of Information Systems program\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Casual Lecturer\",\n",
            "      \"institution\": \"Department of Computer Science & Computer Engineering, La Trobe University\",\n",
            "      \"location\": \"Australia\",\n",
            "      \"date\": \"Feb. 2023–Jun. 2023\",\n",
            "      \"responsibilities\": [\n",
            "        \"Lectured four postgraduate subjects\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Full-time Postdoc\",\n",
            "      \"institution\": \"La Trobe Cybersecurity Research Hub, La Trobe University\",\n",
            "      \"location\": \"Australia\",\n",
            "      \"date\": \"Aug. 2021–May 2022\",\n",
            "      \"responsibilities\": [\n",
            "        \"Worked on 'Anomaly Detection in IoT for Satellite Security Using Blockchain'\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Full-time Postdoc\",\n",
            "      \"institution\": \"Data Science Group, National Institute for Materials Science\",\n",
            "      \"location\": \"Japan\",\n",
            "      \"date\": \"Apr. 2018–Mar. 2020\",\n",
            "      \"responsibilities\": [\n",
            "        \"Participated in 'Materials Research by Information Integration Initiative (MI2I)\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Full-time Postdoc\",\n",
            "      \"institution\": \"Graduate School of Advanced Science and Technology, Japan Advanced Institute of Science and Technology\",\n",
            "      \"location\": \"Japan\",\n",
            "      \"date\": \"May 2017–Mar. 2018\",\n",
            "      \"responsibilities\": [\n",
            "        \"Joined 'Materials Research by Information Integration Initiative (MI2I)'\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Full-time Lecturer\",\n",
            "      \"institution\": \"Faculty of Computer Science and Engineering, Ho Chi Minh City University of Technology\",\n",
            "      \"location\": \"Vietnam\",\n",
            "      \"date\": \"May 2007–Mar. 2013\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Full-time Lecturer\",\n",
            "      \"institution\": \"NIIT Hoa Sen, Hoa Sen University\",\n",
            "      \"location\": \"Vietnam\",\n",
            "      \"date\": \"Dec. 2004–Jan. 2007\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Full-time Developer\",\n",
            "      \"institution\": \"Center for Developing Information Technology and Geographic Information System, Ho Chi Minh City University of Technology\",\n",
            "      \"location\": \"Vietnam\",\n",
            "      \"date\": \"Feb. 2002–Nov. 2004\"\n",
            "    }\n",
            "  ],\n",
            "  \"computer_skills\": {\n",
            "    \"ai_ml\": [\n",
            "      \"Google Colab\",\n",
            "      \"Jupyter Notebook\",\n",
            "      \"TensorFlow\",\n",
            "      \"PyTorch\",\n",
            "      \"GitHub\"\n",
            "    ],\n",
            "    \"programming_languages\": [\n",
            "      \"Python\",\n",
            "      \"C++\",\n",
            "      \"C\",\n",
            "      \"C#\",\n",
            "      \"SQL\",\n",
            "      \"Visual Prolog\"\n",
            "    ],\n",
            "    \"dbms\": [\n",
            "      \"Microsoft SQL Server\",\n",
            "      \"Oracle\",\n",
            "      \"PostgreSQL\"\n",
            "    ]\n",
            "  },\n",
            "  \"selected_publications\": [\n",
            "    {\n",
            "      \"year\": 2024,\n",
            "      \"authors\": \"Nguyen, V.D., Diro, A.A., Chilamkurti, N.K., Heyne, W. and Phan, K.T.\",\n",
            "      \"title\": \"A Novel Blockchain-Enabled Federated Learning Scheme for IoT Anomaly Detection\",\n",
            "      \"journal\": \"IEEE Transactions on Emerging Topics in Computational Intelligence\",\n",
            "      \"status\": \"Major revision\"\n",
            "    },\n",
            "    {\n",
            "      \"year\": 2024,\n",
            "      \"authors\": \"Pham, D., Phan, K.T., Abuadbba, S., Nguyen, V.D., Chilamkurti, N.K.\",\n",
            "      \"title\": \"Split Learning without Local Weight Sharing to Enhance Client-side Data Privacy\",\n",
            "      \"journal\": \"IEEE Transactions on Dependable and Secure Computing\",\n",
            "      \"status\": \"Major revision\"\n",
            "    },\n",
            "    {\n",
            "      \"year\": 2021,\n",
            "      \"authors\": \"Diro, A.A., Chilamkurti, N.K., Nguyen, V.D. and Heyne, W.\",\n",
            "      \"title\": \"A Comprehensive Study of Anomaly Detection Schemes in IoT Networks Using Machine Learning Algorithms\",\n",
            "      \"journal\": \"Sensors\",\n",
            "      \"volume\": \"21\",\n",
            "      \"issue\": \"24\",\n",
            "      \"pages\": \"8320\"\n",
            "    }\n",
            "  ],\n",
            "  \"references\": [\n",
            "    {\n",
            "      \"name\": \"Professor Naveen Chilamkurti\",\n",
            "      \"institution\": \"La Trobe University\",\n",
            "      \"location\": \"Australia\",\n",
            "      \"phone\": \"+61394791269\",\n",
            "      \"email\": \"n.chilamkurti@latrobe.edu.au\",\n",
            "      \"homepage\": \"https://scholars.latrobe.edu.au/nkchilamkurt\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Dr. Abebe Diro\",\n",
            "      \"title\": \"Lecturer\",\n",
            "      \"institution\": \"RMIT University\",\n",
            "      \"location\": \"Australia\",\n",
            "      \"phone\": \"+61399254132\",\n",
            "      \"email\": \"abebe.diro3@rmit.edu.au\",\n",
            "      \"homepage\": \"https://academics.rmit.edu.au/abebe-diro3\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Professor Van-Nam Huynh\",\n",
            "      \"institution\": \"Japan Advanced Institute of Science and Technology\",\n",
            "      \"location\": \"Japan\",\n",
            "      \"phone\": \"+81761511791\",\n",
            "      \"email\": \"huynh@jaist.ac.jp\",\n",
            "      \"homepage\": \"https://www.jaist.ac.jp/~huynh\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Cleaned model output: \n",
            "{\n",
            "  \"name\": \"John Doe\",\n",
            "  \"contact\": {\n",
            "    \"location\": \"Your Location\",\n",
            "    \"email\": \"youremail@yourdomain.com\",\n",
            "    \"phone\": \"0541 999 99 99\",\n",
            "    \"website\": \"yourwebsite.com\",\n",
            "    \"linkedin\": \"linkedin.com/in/yourusername\",\n",
            "    \"github\": \"github.com/yourusername\"\n",
            "  },\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"BS\",\n",
            "      \"institution\": \"University of Pennsylvania\",\n",
            "      \"field\": \"Computer Science\",\n",
            "      \"gpa\": \"3.9/4.0\",\n",
            "      \"coursework\": [\n",
            "        \"Computer Architecture\",\n",
            "        \"Comparison of Learning Algorithms\",\n",
            "        \"Computational Theory\"\n",
            "      ],\n",
            "      \"dates\": \"Sept 2000 – May 2005\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"employer\": \"Apple\",\n",
            "      \"title\": \"Software Engineer\",\n",
            "      \"location\": \"Cupertino, CA\",\n",
            "      \"dates\": \"June 2005 – Aug 2007\",\n",
            "      \"responsibilities\": [\n",
            "        \"Reduced time to render user buddy lists by 75% by implementing a prediction algorithm\",\n",
            "        \"Integrated iChat with Spotlight Search by creating a tool to extract metadata from saved chat transcripts and provide metadata to a system-wide search database\",\n",
            "        \"Redesigned chat file format and implemented backward compatibility for search\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"employer\": \"Microsoft\",\n",
            "      \"title\": \"Software Engineer Intern\",\n",
            "      \"location\": \"Redmond, WA\",\n",
            "      \"dates\": \"June 2003 – Aug 2003\",\n",
            "      \"responsibilities\": [\n",
            "        \"Designed a UI for the VS open file switcher (Ctrl-Tab) and extended it to tool windows\",\n",
            "        \"Created a service to provide gradient across VS and VS add-ins, optimizing its performance via caching\",\n",
            "        \"Built an app to compute the similarity of all methods in a codebase, reducing the time from O(n2) to O(nlogn)\",\n",
            "        \"Created a test case generation tool that creates random XML docs from XML Schema\",\n",
            "        \"Automated the extraction and processing of large datasets from legacy systems using SQL and Perl scripts\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"publications\": [\n",
            "    {\n",
            "      \"title\": \"3D Finite Element Analysis of No-Insulation Coils\",\n",
            "      \"authors\": [\"Frodo Baggins\", \"John Doe\", \"Samwise Gamgee\"],\n",
            "      \"doi\": \"10.1109/TASC.2023.3340648\",\n",
            "      \"date\": \"Jan 2004\"\n",
            "    }\n",
            "  ],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"name\": \"Multi-User Drawing Tool\",\n",
            "      \"description\": \"Developed an electronic classroom where multiple users can simultaneously view and draw on a 'chalkboard' with each person’s edits synchronized\",\n",
            "      \"tools\": [\"C++\", \"MFC\"],\n",
            "      \"repository\": \"github.com/name/repo\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Synchronized Desktop Calendar\",\n",
            "      \"description\": \"Developed a desktop calendar with globally shared and synchronized calendars, allowing users to schedule meetings with other users\",\n",
            "      \"tools\": [\"C#\", \".NET\", \"SQL\", \"XML\"],\n",
            "      \"repository\": \"github.com/name/repo\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Custom Operating System\",\n",
            "      \"description\": \"Built a UNIX-style OS with a scheduler, file system, text editor, and calculator\",\n",
            "      \"tools\": [\"C\"],\n",
            "      \"dates\": \"2002\"\n",
            "    }\n",
            "  ],\n",
            "  \"technologies\": {\n",
            "    \"languages\": [\"C++\", \"C\", \"Java\", \"Objective-C\", \"C#\", \"SQL\", \"JavaScript\"],\n",
            "    \"technologies\": [\".NET\", \"Microsoft SQL Server\", \"XCode\", \"Interface Builder\"]\n",
            "  },\n",
            "  \"last_updated\": \"September 2024\"\n",
            "}\n",
            "\n",
            "Cleaned model output: \n",
            "{\n",
            "  \"name\": \"Marissa Mayer\",\n",
            "  \"title\": \"Business Woman & Proud Geek\",\n",
            "  \"contact_information\": {\n",
            "    \"email\": \"mmayer@yahoo-inc.com\",\n",
            "    \"location\": \"Sunnyvale, CA\",\n",
            "    \"website\": \"http://marissamayr.tumblr.com\",\n",
            "    \"twitter\": \"@marissamayer\",\n",
            "    \"linkedin\": \"linkedinmarissamayer\"\n",
            "  },\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"position\": \"President & CEO\",\n",
            "      \"company\": \"Yahoo!\",\n",
            "      \"location\": \"Sunnyvale, CA\",\n",
            "      \"duration\": \"July 2012 – Ongoing\",\n",
            "      \"responsibilities\": [\n",
            "        \"Led the $5 billion acquisition of the company with Verizon.\",\n",
            "        \"Acquired Tumblr for $1.1 billion.\",\n",
            "        \"Built Yahoo’s mobile, video, and social businesses from $0 in 2011 to $1.6 billion in GAAP revenue in 2015.\",\n",
            "        \"Tripled mobile base to over 600 million monthly active users and generated over $1 billion in mobile advertising revenue.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"position\": \"Vice President of Location & Services\",\n",
            "      \"company\": \"Google\",\n",
            "      \"location\": \"Palo Alto, CA\",\n",
            "      \"duration\": \"Oct 2010 – July 2012\",\n",
            "      \"responsibilities\": [\n",
            "        \"Positioned Google Maps as the world leader in mobile apps and navigation.\",\n",
            "        \"Oversaw 1000+ engineers and product managers working on Google Maps, Google Places, and Google Earth.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"position\": \"Vice President of Search Products & UX\",\n",
            "      \"company\": \"Google\",\n",
            "      \"location\": \"Palo Alto, CA\",\n",
            "      \"duration\": \"2005 – 2010\"\n",
            "    },\n",
            "    {\n",
            "      \"position\": \"Product Manager & UI Lead\",\n",
            "      \"company\": \"Google\",\n",
            "      \"location\": \"Palo Alto, CA\",\n",
            "      \"duration\": \"Oct 2001 – July 2005\",\n",
            "      \"responsibilities\": [\n",
            "        \"Appointed by Larry Page to lead the Product Management and User Interaction teams.\",\n",
            "        \"Optimized Google’s homepage and A/B tested every minor detail to increase usability.\"\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"daily_routine\": [\n",
            "    \"Sleeping & dreaming about work\",\n",
            "    \"Resolving issues with Yahoo! investors\",\n",
            "    \"Ballet\",\n",
            "    \"Jawbone board member\",\n",
            "    \"Spending time with family\",\n",
            "    \"Business development for Yahoo! after the Verizon acquisition\",\n",
            "    \"Showing Yahoo! employees that their work has meaning\",\n",
            "    \"Baking cupcakes\"\n",
            "  ],\n",
            "  \"life_philosophy\": \"If you don’t have any shadows, you’re not standing in the light.\",\n",
            "  \"achievements\": [\n",
            "    \"Courage to take a sinking ship and try to make it float.\",\n",
            "    \"Persistence & Loyalty shown despite hard moments with willingness to stay with Yahoo after the acquisition.\",\n",
            "    \"Google's Growth from a hundred thousand searches per day to over a billion.\",\n",
            "    \"Inspiring women in tech.\",\n",
            "    \"Youngest CEO on Fortune’s list of 50 most powerful women.\"\n",
            "  ],\n",
            "  \"strengths\": [\n",
            "    \"Hard-working (18/24)\",\n",
            "    \"Persuasive\",\n",
            "    \"Motivator & Leader\",\n",
            "    \"UX Mobile Devices & Applications\",\n",
            "    \"Product Management & Marketing\"\n",
            "  ],\n",
            "  \"languages\": {\n",
            "    \"English\": 5,\n",
            "    \"Spanish\": 5,\n",
            "    \"German\": 4\n",
            "  },\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"M.S. in Computer Science\",\n",
            "      \"institution\": \"Stanford University\",\n",
            "      \"duration\": \"Sept 1997 – June 1999\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"B.S. in Symbolic Systems\",\n",
            "      \"institution\": \"Stanford University\",\n",
            "      \"duration\": \"Sept 1993 – June 1997\"\n",
            "    }\n",
            "  ],\n",
            "  \"publications\": [\n",
            "    {\n",
            "      \"type\": \"Books\",\n",
            "      \"title\": \"A Fictional Research\",\n",
            "      \"authors\": [\"E. Someone\", \"T. Lim\"],\n",
            "      \"location\": \"Somewhere, Some Place\",\n",
            "      \"year\": 2010\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"Journal Articles\",\n",
            "      \"title\": \"A non-existant paper\",\n",
            "      \"authors\": [\"L. T. Wong\", \"E. Someone\"],\n",
            "      \"journal\": \"Journal of Carrying On\",\n",
            "      \"volume\": 12,\n",
            "      \"year\": 2011\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"Journal Articles\",\n",
            "      \"title\": \"A study into fireside storytelling\",\n",
            "      \"authors\": [\"L. T. Lim\", \"E. Someone\", \"A. Other\"],\n",
            "      \"journal\": \"Journal of Carrying On\",\n",
            "      \"volume\": 7,\n",
            "      \"year\": 2008\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"Conference Proceedings\",\n",
            "      \"title\": \"Another paper something something\",\n",
            "      \"authors\": [\"E. Someone\", \"L. T. Lim\"],\n",
            "      \"conference\": \"Proceedings of the 72nd AmaZing Conference\",\n",
            "      \"location\": \"Far Far Away\",\n",
            "      \"year\": 2013\n",
            "    }\n",
            "  ],\n",
            "  \"referees\": [\n",
            "    {\n",
            "      \"name\": \"Prof. Alpha Beta\",\n",
            "      \"institution\": \"Institute\",\n",
            "      \"email\": \"a.beta@university.edu\",\n",
            "      \"address\": [\"Address Line 1\", \"Address line 2\"]\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Prof. Gamma Delta\",\n",
            "      \"institution\": \"Institute\",\n",
            "      \"email\": \"g.delta@university.edu\",\n",
            "      \"address\": [\"Address Line 1\", \"Address line 2\"]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Excel file 'output.xlsx' with each CV in a separate sheet has been saved to /content/drive/MyDrive/UNI/VU/PDFs/output.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9USCE-m0JNS9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXnQRrXlJNWG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3BLCBF5WJNYj"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}